"use strict";(self.webpackChunkwhg_training_resources=self.webpackChunkwhg_training_resources||[]).push([[3540],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return h}});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,s=e.originalType,l=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),m=c(a),h=i,d=m["".concat(l,".").concat(h)]||m[h]||u[h]||s;return a?n.createElement(d,r(r({ref:t},p),{},{components:a})):n.createElement(d,r({ref:t},p))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var s=a.length,r=new Array(s);r[0]=m;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:i,r[1]=o;for(var c=2;c<s;c++)r[c]=a[c];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},2017:function(e,t,a){a.r(t),a.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return h},frontMatter:function(){return o},metadata:function(){return c},toc:function(){return u}});var n=a(7462),i=a(3366),s=(a(7294),a(3905)),r=["components"],o={},l="Bayesian meta-analysis practical",c={unversionedId:"statistical_modelling/Introduction/practicals/bayesian_meta_analysis/bayesian_meta_analysis_practical",id:"statistical_modelling/Introduction/practicals/bayesian_meta_analysis/bayesian_meta_analysis_practical",title:"Bayesian meta-analysis practical",description:"In this practical we will investigate a simple method to investigate sharing of genetic effects between traits.",source:"@site/docs/statistical_modelling/Introduction/practicals/bayesian_meta_analysis/bayesian_meta_analysis_practical.md",sourceDirName:"statistical_modelling/Introduction/practicals/bayesian_meta_analysis",slug:"/statistical_modelling/Introduction/practicals/bayesian_meta_analysis/bayesian_meta_analysis_practical",permalink:"/whg-training-resources/statistical_modelling/Introduction/practicals/bayesian_meta_analysis/bayesian_meta_analysis_practical",draft:!1,editUrl:"https://github.com/whg-training/whg-training-resources/docs/statistical_modelling/Introduction/practicals/bayesian_meta_analysis/bayesian_meta_analysis_practical.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"A tale of two 2x2 tables",permalink:"/whg-training-resources/statistical_modelling/Introduction/practicals/a_tale_of_two_2x2_tables/introduction"},next:{title:"atp2b4_practical",permalink:"/whg-training-resources/statistical_modelling/Introduction/practicals/linear_regression/atp2b4/atp2b4_practical"}},p={},u=[{value:"Loading the data",id:"loading-the-data",level:2},{value:"Computing Bayes factors",id:"computing-bayes-factors",level:2},{value:"Choosing priors and weights",id:"choosing-priors-and-weights",level:2},{value:"Computing BFs",id:"computing-bfs",level:2},{value:"Summarising by count",id:"summarising-by-count",level:3},{value:"Summarising by phenotype",id:"summarising-by-phenotype",level:3},{value:"Interesting findings",id:"interesting-findings",level:2},{value:"Caution",id:"caution",level:2},{value:"Empirical Bayes",id:"empirical-bayes",level:2}],m={toc:u};function h(e){var t=e.components,a=(0,i.Z)(e,r);return(0,s.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"bayesian-meta-analysis-practical"},"Bayesian meta-analysis practical"),(0,s.kt)("p",null,"In this practical we will investigate a simple method to investigate sharing of genetic effects between traits.\nSpecifically we will investigate 107 SNPs that have been associated with seven autoimmune-related conditions (from ",(0,s.kt)("a",{parentName:"p",href:"https://doi.org/10.1371/journal.pgen.1002254"},"https://doi.org/10.1371/journal.pgen.1002254"),"), and for each SNP ask: are these effects restricted to a single trait, shared across all traits, or somewhere in between?"),(0,s.kt)("p",null,"To do this we will use a simple Bayesian method in which we consider all possible models of effect sharing across traits and\ncompute the evidence in the data for each model.  Like our other Bayesian analyses so far, we will do this by specifying prior parameters\ngenerated by making reasonable guesses."),(0,s.kt)("p",null,"We use data from Cotsapas et al PLoS Genetics (2011)\nData is effect size estimates and standard errors for 107 SNPs and 7 autoimmune traits.  We'd like to know - to what extent are genetic effects shared across these traits?"),(0,s.kt)("p",null,"To answer this we'll use a Bayesian approach to meta-analysis across traits.  This considers all models of association with one trait, with two traits, and so on up to all traits.  It uses Bayes Factors to compute relative strengths of evidence."),(0,s.kt)("p",null,"Using Bayes factors allows us to make nice computations of posterior weights."),(0,s.kt)("h2",{id:"loading-the-data"},"Loading the data"),(0,s.kt)("p",null,"Load the data and get the reported effect size estimates (betas), standard errors, and P-values as follows:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},'cotsapas = load( "practicals/cotsapas_data.RData")\nrownames( cotsapas ) = cotsapas$SNP\nbetas = as.matrix( cotsapas[, grep( ".beta", colnames( cotsapas ))] )\nses = as.matrix( cotsapas[, grep( ".SE", colnames( cotsapas ))] )\nPs = as.matrix( cotsapas[, grep( "[.]P", colnames( cotsapas ))] )\nphenotypes = gsub( ".beta", "", grep( ".beta", colnames( cotsapas ), value = T ), fixed = T )\n')),(0,s.kt)("h2",{id:"computing-bayes-factors"},"Computing Bayes factors"),(0,s.kt)("p",null,"According to the lemma about multiplying multivariate normals (MVNs) - see the ","[Normal times normal\nis normal]","(../../notes/Normal times normal is normal.pdf) document, the product of an MVN prior and\nan MVN likelihood is equal to an MVN multiplied by a constant. And the constant is itself\ncomputable by an MVN evaluated at the effect size estimate."),(0,s.kt)("p",null,"We use the ",(0,s.kt)("inlineCode",{parentName:"p"},"mvtnorm")," package to compute this for any given model, specificed as a 7x7 prior\ncovariance matrix, against the null model under which all true effects are zero."),(0,s.kt)("p",null,"(The implemention below additionally deals with missing beta estimates)."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"library( mvtnorm )\ncompute.bf <- function( betas, ses, prior ) {\n    w = which( !is.na( betas ))\n    dmvnorm(\n        betas[w],\n        sigma = prior[w,w] + diag( ses[w]^2 )\n    ) / dmvnorm(\n        betas[w],\n        sigma = diag( ses[w]^2 )\n    )\n}\n")),(0,s.kt)("h2",{id:"choosing-priors-and-weights"},"Choosing priors and weights"),(0,s.kt)("p",null,"We will evaluate every possible combination of trait associations - the ",(0,s.kt)("inlineCode",{parentName:"p"},"expand.grid()")," function\ncan be used to enumerate these:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},'priors = expand.grid(\n    RA = c(0,1),\n    PS = c(0,1),\n    MS = c(0,1),\n    SLE = c(0,1),\n    CD = c(0,1),\n    CeD = c(0,1),\n    T1D = c(0,1)\n)\nrownames( priors ) = sapply( 1:nrow( priors ), function(i) { paste( priors[i,], collapse = "" )})\npriors = priors[-1,] # remove the null model\nhead(priors)\n')),(0,s.kt)("p",null,"For our initial analysis we will weight each model such that there is the same prior\nthat k phenotypes are associated, for each k = 1,... 7."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"prior.phenotype.counts = rowSums( priors )\nweights = matrix(\n    sapply( prior.phenotype.counts, function( count ) { 1 / length( which( prior.phenotype.counts == count ))}),\n    nrow = 1\n) / 7\n")),(0,s.kt)("p",null,"This prior weighting means there is more weight on (say) the single model of all traits, than there is on each of the 7 models of association with a single trait, or the (7 choose k) models of association with k traits (1 < k < 7)."),(0,s.kt)("p",null,"This function is used to compute prior matrices for any given prior from the above table:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"compute.prior.matrix <- function( row, rho = 0.9, sd = 0.2 ) {\n    prior = matrix( 0, 7, 7 )\n    w = which( row == 1 )\n    prior[w,w] = rho * sd^2\n    diag(prior)[w] = sd^2\n    return( prior )\n}\n")),(0,s.kt)("p",null,"The prior matrix has a nonzero variance in the diagonal entries corresponding to 1's in the priors\ntable. And it assumes a correlation (by default 0.9) between the effects with nonzero variance."),(0,s.kt)("h2",{id:"computing-bfs"},"Computing BFs"),(0,s.kt)("p",null,"We have to compute 127 BFs for each of 107 SNPs.  Let's do it in a loop and store it in a matrix."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"bfs = matrix( NA, nrow( cotsapas ), nrow( priors ),\n    dimnames = list( cotsapas$SNP, rownames( priors ))\n)\nsd = 0.2\nfor( i in 1:nrow( cotsapas )) {\n    beta_hat = betas[i,]\n    se = ses[i,]\n    for( j in 1:nrow(priors)) {\n        prior = compute.prior( priors[j,] )\n        bfs[i,j] = compute.bf( beta_hat, se, prior )\n    }\n}\n")),(0,s.kt)("p",null,"The BFs represent evidence against the null.  Here, we aren't interested in the null model (all SNPs have been chosen because they are associated).  But we are interested in the posterior probability of each model.  We can compute that by a) multiplying by the prior weights and b) normalising so that posteriors sum to 1:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"posteriors = matrix( NA, nrow( cotsapas ), nrow( priors ),\n    dimnames = list( cotsapas$SNP, rownames( priors ))\n)\nfor( i in 1:nrow( posteriors ) ) {\n    posteriors[i,] = bfs[i,] * weights\n    posteriors[i,] = posteriors[i,] / sum( posteriors[i,], na.rm = T )\n}\n")),(0,s.kt)("p",null,"##\xa0Summarising the analysis"),(0,s.kt)("p",null,"Now we can get some information out."),(0,s.kt)("h3",{id:"summarising-by-count"},"Summarising by count"),(0,s.kt)("p",null,"First, we could look at how many traits are associated in general.\nTo compute this we summarise by adding up the models with a given number of traits:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"# Compute posterior on each number of effects\nbyCount = matrix(\n    0,\n    nrow = nrow( priors ),\n    ncol = 7,\n    dimnames = list( rownames( priors ), 1:7 )\n)\nfor( n in 1:7 ) {\n    byCount[ which( prior.phenotype.counts == n ),i] = 1\n}\ncount.posteriors = posteriors %*% byCount\n")),(0,s.kt)("p",null,"For example we could find SNPs where there is evidence for more than one effect:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"which( sum( count.posteriors[,2:7] ) > count.posteriors[,1] )\n")),(0,s.kt)("h3",{id:"summarising-by-phenotype"},"Summarising by phenotype"),(0,s.kt)("p",null,"We could also summarise by phenotype - e.g. to find SNPs consistent with an effect for a given phenotype:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"byPhenotype = matrix(\n    0,\n    nrow = nrow( priors ),\n    ncol = 7,\n    dimnames = list( rownames( priors ), phenotypes )\n)\nfor( i in 1:7 ) {\n    byPhenotype[which( priors[,i] == 1 ),i] = 1\n}\nphenotype.posteriors = posteriors %*% byPhenotype\n")),(0,s.kt)("p",null,"E.g. to find the expected number of associations per phenotype:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"colSums( phenotype.posteriors )\n")),(0,s.kt)("p",null,"(Chrohn's disease has the most)"),(0,s.kt)("h2",{id:""}),(0,s.kt)("p",null,"How many SNPs have (say) > twice, or greater than 10 times the posterior mass on models with at least 2 effects?"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"length( which( rowSums( count.posteriors[,2:7] ) > 2 * count.posteriors[,1] ) )\nlength( which( rowSums( count.posteriors[,2:7] ) > 10 * count.posteriors[,1] ) )\n")),(0,s.kt)("p",null,"Compare our results with those of Cotsapas et al paper.  They identified 47 SNPs with evidence of more than one association.  Their method, though, looked for statistical significance of >1 effect and didn't take into account effect size sharing.  Which of these is right?  Is either right?"),(0,s.kt)("h2",{id:"interesting-findings"},"Interesting findings"),(0,s.kt)("p",null,"Some SNPs are identified as having effects on all traits - yet have very non-significant P-values:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"count.posteriors['rs11755527',]\nphenotype.posteriors['rs11755527',]\nbetas['rs11755527',]\nses['rs11755527',]\nPs['rs11755527',]\n")),(0,s.kt)("p",null,"What does this mean?  "),(0,s.kt)("p",null,"Presumably, the -ve estimates for MS and CD imply that other -ve estimates appear likely under our model.  So our analysis concludes there are effects on all phenotypes.  (This is despite us assuming a +ve correlation between effects - this is not a strong condition in a MVN.)"),(0,s.kt)("h2",{id:"caution"},"Caution"),(0,s.kt)("p",null,"This analysis highlights a typical aspect of a Bayesian analysis - it requires some thought.\nThis is both a burden on the bayesian analyst, but also a great advantage (c.f. the discussion in lectures of statistical and conceptual models).  In short you will have to do the thought anyway and this is a good place to do it."),(0,s.kt)("p",null,"Here, we have a particular prior assumption that each number of associations has equal weight.\nIs that realistic?"),(0,s.kt)("p",null,"We also have a prior assumption on the correlation between traits - is that realistic?"),(0,s.kt)("h2",{id:"empirical-bayes"},"Empirical Bayes"),(0,s.kt)("p",null,"We could now implement an 'empirical Bayes' approach by learning new model weights using all the SNPs we've seen:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-R"},"empirical.weights = colSums( posteriors )\n")),(0,s.kt)("p",null,"We would then recompute BFs using the empirical weights."))}h.isMDXComponent=!0}}]);