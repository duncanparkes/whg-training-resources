"use strict";(self.webpackChunkwhg_training_resources=self.webpackChunkwhg_training_resources||[]).push([[1995],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return m}});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(n),m=i,h=c["".concat(l,".").concat(m)]||c[m]||d[m]||r;return n?a.createElement(h,o(o({ref:t},u),{},{components:n})):a.createElement(h,o({ref:t},u))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var p=2;p<r;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},5541:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return s},metadata:function(){return p},toc:function(){return d}});var a=n(7462),i=n(3366),r=(n(7294),n(3905)),o=["components"],s={},l=void 0,p={unversionedId:"genome_wide_association_studies/Meta-analysis and fine-mapping/Introduction",id:"genome_wide_association_studies/Meta-analysis and fine-mapping/Introduction",title:"Introduction",description:"Up to the table of contents - Forward to the meta-analysis section",source:"@site/docs/genome_wide_association_studies/Meta-analysis and fine-mapping/Introduction.md",sourceDirName:"genome_wide_association_studies/Meta-analysis and fine-mapping",slug:"/genome_wide_association_studies/Meta-analysis and fine-mapping/Introduction",permalink:"/whg-training-resources/genome_wide_association_studies/Meta-analysis and fine-mapping/Introduction",draft:!1,editUrl:"https://github.com/whg-training/whg-training-resources/docs/genome_wide_association_studies/Meta-analysis and fine-mapping/Introduction.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Fine-mapping",permalink:"/whg-training-resources/genome_wide_association_studies/Meta-analysis and fine-mapping/Fine-mapping"},next:{title:"Meta-analysis",permalink:"/whg-training-resources/genome_wide_association_studies/Meta-analysis and fine-mapping/Meta-analysis"}},u={},d=[{value:"Meta-analysis and fine-mapping practical",id:"meta-analysis-and-fine-mapping-practical",level:2},{value:"Getting the data",id:"getting-the-data",level:3}],c={toc:d};function m(e){var t=e.components,n=(0,i.Z)(e,o);return(0,r.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"/whg-training-resources/genome_wide_association_studies/Meta-analysis%20and%20fine-mapping/"},"Up to the table of contents")," - ",(0,r.kt)("a",{parentName:"p",href:"/whg-training-resources/genome_wide_association_studies/Meta-analysis%20and%20fine-mapping/Meta-analysis"},"Forward to the meta-analysis section")),(0,r.kt)("h2",{id:"meta-analysis-and-fine-mapping-practical"},"Meta-analysis and fine-mapping practical"),(0,r.kt)("p",null,"So you've run your GWAS and you've found some signals.  Now what?"),(0,r.kt)("p",null,"In this practical we will implement two steps that both try to help narrow down association signals\nto the possible causal variants. In the first of these, we will take data from two studies and\n",(0,r.kt)("em",{parentName:"p"},"meta-analyse")," it to combined the evidence. Then, we will use a fine-mapping method to try to identify a variant or variants that have the most evidence."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note"),". Why can't we just use the P-values from the study directly, and pick the smallest?  Well maybe that would work, but there are two reasons to try something else:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"There might be more than one causal variant."),(0,r.kt)("li",{parentName:"ul"},"The P-values reflect a mixture of ",(0,r.kt)("em",{parentName:"li"},"effect size")," and ",(0,r.kt)("em",{parentName:"li"},"allele frequency"),".  They might not be the best way to identify the underlying variants.")),(0,r.kt)("h3",{id:"getting-the-data"},"Getting the data"),(0,r.kt)("p",null,"The data for this practical is in two files, ",(0,r.kt)("inlineCode",{parentName:"p"},"study1.z")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"study2.z"),".  Load them now and take a look:"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note.")," I am using the ",(0,r.kt)("a",{parentName:"p",href:"https://www.tidyverse.org"},"tidyverse")," for these examples.  If you don't have that or don't want to get it, you can use base R functions like ",(0,r.kt)("inlineCode",{parentName:"p"},"read.table()")," instead."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'library(tidyverse)\nstudy1 = read_delim( "study1.z", delim = " " )\nstudy2 = read_delim( "study2.z", delim = " " )\n\n')),(0,r.kt)("p",null,"Look at the data using ",(0,r.kt)("inlineCode",{parentName:"p"},"head()")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"View()"),"."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Question.")," What's in the data?  How many SNPs?"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note.")," For the analysis to work, the files will need to have the same SNPs in the same order.  Check this now!  (For example, you could check that ",(0,r.kt)("inlineCode",{parentName:"p"},"length( which( study1$rsid != study2$rsid ) )")," is zero.)"),(0,r.kt)("p",null,"The data for each study consists of:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"the rsid, chromosome, position and alleles of each SNP"),(0,r.kt)("li",{parentName:"ul"},"the minor allele frequency (",(0,r.kt)("inlineCode",{parentName:"li"},"maf"),") of each SNP"),(0,r.kt)("li",{parentName:"ul"},"and the GWAS / regression summary statistics, i.e. the maximum likelihood estimate ",(0,r.kt)("em",{parentName:"li"},"\u03b2")," and its standard error ",(0,r.kt)("inlineCode",{parentName:"li"},"s"),", for the association test of the SNP against the phenotype.")),(0,r.kt)("p",null,"The data is for a region of the genome (overing ",(0,r.kt)("em",{parentName:"p"},"FUT2"),") where an association has been found."),(0,r.kt)("p",null,"The data doesn't contain any P-values or Bayes factors. However, if you joined the regression\npractical earlier you will know how to compute them:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  study1$P = pnorm( -abs(study1$beta), sd = study1$se ) * 2\n  study2$P = pnorm( -abs(study2$beta), sd = study2$se ) * 2\n")),(0,r.kt)("p",null,"and similarly for study2. The expression above computes the mass under the two tails with effect >=\n",(0,r.kt)("em",{parentName:"p"},"\u03b2"),", of the gaussian distribution with standard deviation = the standard error. I.e. it is a\nP-value using the effect size estimate as a test statistic."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note.")," We could also compute a Bayes factor.  For example, suppose we believe in relatively small effects, so choose a ",(0,r.kt)("em",{parentName:"p"},"N(0,0.2",(0,r.kt)("sup",null,"2"),")")," prior.  The calculation is:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"compute.bf <- function( beta, se, prior.variance ) {\n  (\n    pnorm( beta, mean = 0, sd = sqrt( se^2 + 0.2 ) )\n    /\n    pnorm( beta, mean = 0, sd = se )\n  )\n}\n\nstudy1$log10_BF = log10( compute.bf( study1$beta, study1$se ))\nstudy2$log10_BF = log10( compute.bf( study2$beta, study2$se ))\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Question.")," How much evidence is there in the two studies? Are any of the most-associated SNPs\nshared between the two studies?"),(0,r.kt)("p",null,"When you're ready, ",(0,r.kt)("a",{parentName:"p",href:"/whg-training-resources/genome_wide_association_studies/Meta-analysis%20and%20fine-mapping/Meta-analysis"},"start meta-analysing"),"."))}m.isMDXComponent=!0}}]);